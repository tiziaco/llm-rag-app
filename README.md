# llm-rag-app

This project consists of a chatbot application created in Streamlit. The local language model (LLM) and the Retrieval-Augmented Generation (RAG) are implemented using the framework 'llama index'. 


## Key Features:

- **Interactive Chatbot:** Interact with the LLM through a user-friendly Streamlit interface.
- **Local LLM Support:** Choose and utilize your preferred local LLM model (including Llama2).
- **Contextual Control:** Modify the context provided to the LLM for more focused information extraction.
- **Customizable Parameters:** Fine-tune LLM behavior by adjusting parameters like temperature.
- **Configurable RAG:** Select text splitters and embedding models to tailor information retrieval to your specific needs.


## Usage

To use the chatbot:

1. Clone the repository.
2. Install dependencies.
3. Run the application.
4. Interact with the chatbot interface.

## Development

Feel free to extend this project by:

- Integrating additional functionality, such as direct PDF processing or different information extraction methods.
- Experimenting with different LLM and RAG configurations.
- Improving the user interface for a more intuitive experience.
